{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from lightning import LightningModule, Trainer\n",
    "from dataloader import InsectDatamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from lightning import LightningModule\n",
    "\n",
    "class ResBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, n_max_pool: int, **kwargs):\n",
    "        super().__init__()\n",
    "        padding = kernel_size // 2\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding='same', **kwargs)\n",
    "        self.batchnorm1 = torch.nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, padding='same', **kwargs)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.maxpool = torch.nn.MaxPool2d(kernel_size=n_max_pool, stride=n_max_pool)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.batchnorm2(out)\n",
    "        out = self.relu(out) + x\n",
    "        return self.maxpool(out)\n",
    "\n",
    "\n",
    "class ResNet(LightningModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "            out_channels: int,\n",
    "            kernel_size: int,\n",
    "            n_max_pool: int,\n",
    "            n_res_blocks: int,\n",
    "            num_classes: int,\n",
    "            learning_rate: float = 0.001,\n",
    "            **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding='same', **kwargs)\n",
    "        self.batchnorm1 = torch.nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.res_blocks = torch.nn.Sequential(\n",
    "            *[ResBlock(\n",
    "                in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, n_max_pool=n_max_pool, **kwargs) for _ in range(n_res_blocks)]\n",
    "        )\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.convout = torch.nn.Conv2d(in_channels=out_channels, out_channels=num_classes, kernel_size=1, **kwargs)\n",
    "\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "        self.cross_entropy_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (N, C=1, H, W)\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        # Run input through a first convolutional layer.\n",
    "        out = self.conv1(x)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        # Run input through the residual blocks.\n",
    "        out = self.res_blocks(out)\n",
    "\n",
    "        # Run input through the average pooling layer. The output is a tensor of shape (N, C, 1, 1).\n",
    "        out = self.avgpool(out)\n",
    "\n",
    "        # Run input through the output convolutional layer. This is the same as a fully connected layer but it works with 4D tensors.\n",
    "        out = self.convout(out)\n",
    "\n",
    "        # Flatten the output tensor to have shape (N, C).\n",
    "        out  = out.flatten(1)\n",
    "\n",
    "        out = self.softmax(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def accuracy(self, y_hat, y):\n",
    "        labels_hat = torch.argmax(y_hat, dim=1)\n",
    "        labels = torch.argmax(y, dim=1)\n",
    "        return torch.sum(labels == labels_hat).item() / (len(y) * 1.0)\n",
    "\n",
    "    def cross_entropy(self, y_hat, y):\n",
    "        return self.cross_entropy_loss_fn(y_hat, y.float())\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x, y = batch\n",
    "\n",
    "        y_hat = self(x)\n",
    "\n",
    "        loss = self.cross_entropy(y_hat, y)\n",
    "\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log_dict({'train_loss': loss, 'train_acc': self.accuracy(y_hat, y)})\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x, y = batch\n",
    "\n",
    "        y_hat = self(x)\n",
    "\n",
    "        loss = self.cross_entropy(y_hat, y)\n",
    "\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log_dict({'val_loss': loss, 'val_acc': self.accuracy(y_hat, y)})\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.learning_rate, weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the datamodule\n",
    "\n",
    "csv_paths = ['../data/Cicadidae.csv', '../data/Orthoptera.csv']\n",
    "\n",
    "batch_size = 10\n",
    "num_workers = 0\n",
    "\n",
    "n_fft = 1000\n",
    "hop_length =  147\n",
    "win_length = int(hop_length * 2)\n",
    "n_mels = 64\n",
    "\n",
    "datamodule = InsectDatamodule(\n",
    "    csv_paths = csv_paths, batch_size = batch_size, num_workers = num_workers, hop_length = hop_length, n_fft = n_fft, win_length = win_length, n_mels = n_mels)\n",
    "\n",
    "resnet = ResNet(\n",
    "    in_channels=1, out_channels=32, kernel_size=3, n_max_pool=3, n_res_blocks=3, num_classes=datamodule.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kraft\\.conda\\envs\\torch_cuda\\Lib\\site-packages\\lightning\\pytorch\\loops\\utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type              | Params\n",
      "------------------------------------------------------------\n",
      "0 | conv1                 | Conv2d            | 320   \n",
      "1 | batchnorm1            | BatchNorm2d       | 64    \n",
      "2 | relu                  | ReLU              | 0     \n",
      "3 | res_blocks            | Sequential        | 55.9 K\n",
      "4 | avgpool               | AdaptiveAvgPool2d | 0     \n",
      "5 | convout               | Conv2d            | 1.1 K \n",
      "6 | softmax               | Softmax           | 0     \n",
      "7 | cross_entropy_loss_fn | CrossEntropyLoss  | 0     \n",
      "------------------------------------------------------------\n",
      "57.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "57.3 K    Total params\n",
      "0.229     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kraft\\.conda\\envs\\torch_cuda\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kraft\\.conda\\envs\\torch_cuda\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\kraft\\.conda\\envs\\torch_cuda\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:298: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48:  38%|███▊      | 8/21 [00:02<00:03,  3.62it/s, v_num=2] "
     ]
    }
   ],
   "source": [
    "trainer.fit(resnet, train_dataloaders=datamodule.train_dataloader(), val_dataloaders=datamodule.val_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
