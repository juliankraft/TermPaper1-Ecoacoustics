% Indicate the main file. Must go at the beginning of the file.
% !TEX root = ../main.tex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{section1}

\subsection{Background}

The question about biodiversity and its importance has been a topic of interest for many years. 
The term biodiversity is a contraction of biological diversity, which refers to the variety and variability of life forms on Earth.
In recent years, a massive decline in biodiversity has been observed, which is mainly due to human activities. 
The loss of biodiversity is a major concern because it can have a significant impact on the ecosystem and the services it provides \autocite{brondizioGlobalAssessmentReport2019}. 
In order to quantify biodiversity and monitor its changes, it is essential to have a reliable and efficient method for measuring biodiversity.
Traditional methods for measuring biodiversity are time-consuming and expensive, and they are not suitable for large-scale monitoring.
But what if there was a non invasive method that could be used to monitor biodiversity in a fast and efficient way?
Ecoacoustics might deliver a promising solution to this problem even tough there remain some issues to be fixed \autocite{scarpelliMultiIndexEcoacousticsAnalysis2021}.  
Passive acoustic monitoring (PAM) like the using of sound recordings to monitor biodiversity are currently widely researched
and developed and even combined with modern artificial intelligence (AI) methods \autocite{dengHarnessingPowerSound2023}.

The focus of this study is to reproduce the results of the paper \autocite{faissInsectSet32DatasetAutomatic2022} and to create a model 
that can classify the insect sounds with a high accuracy. Furthermore the model will be tested and evaluated for its performance and
accuracy. The results will be discussed and compared to the results of the original paper. The goal is to prof that this technology
could be accessible for everyone with the knowledge and a regular gaming computer with a graphic processing unit (GPU).

\subsection{Insects of Interest}
There are countless species of insects in the world, and many of them produce sounds for various reasons.
In this study, we are interested in the sounds produced by two groups of insects: Orthoptera and Cicadidae.
Orthoptera is an order of insects that includes grasshoppers, crickets, and katydids. \autocite{capineraOrthoptera2008}
Cicadidae, a members of the superfamily Cicadoidea Westwood are four-winged insects with sucking 
mouthparts that possess three ocelli and a rostrum that arises from the base of the head. \autocite{sanbornCicadasHemipteraCicadoidea2008}

\subsection{Dataset}

The dataset used in this study is the InsectSet32 dataset \autocite{faissInsectSet32DatasetAutomatic2022}. 
Containing this description:

This dataset contains recordings of 32 sound producing insect species with a total 335 files and a length of 57 minutes. 
The dataset was compiled for training neural networks to automatically identify insect species while comparing adaptive, 
waveform-based frontends to conventional mel-spectrogram methods for audio feature extraction. 
This work will be submitted for publication in the future and the dataset can be used to replicate the results or for similar research. 
Roughly half of the recordings (147) are of nine species belonging to the order Orthoptera. 
These recordings stem from a dataset that was originally compiled by Baudewijn Od√© (unpublished). 
The remaining recordings (188) are of 23 species in the family Cicadidae. 
These recordings were selected from the Global Cicada Sound Collection hosted on Bioacoustica \autocite{bakerBioAcousticaFreeOpen2015}, 
including recordings published in \autocites{bakerGlobalCicadaSound2015}{poppleRevisionMyopsaltaCrucifera2017}.
Many recordings from this collection included speech annotations in the beginning of the recordings, 
therefore the last ten seconds of audio were extracted and used in this dataset. 
All files were manually inspected and files with strong noise interference or with sounds of multiple species were removed. 
Between species, the number of files ranges from four to 22 files and the length from 40 seconds to almost nine minutes of audio material for a single species. 
The files range in length from less than one second to several minutes. 
All original files were available with sample rates of at least 44.1 kHz or higher but were resampled to 44.1 kHz mono WAV files for consistency.

The files are split into training, validation and test sets. And there are two .csv files containing
the labels and the filenames of the recordings.



