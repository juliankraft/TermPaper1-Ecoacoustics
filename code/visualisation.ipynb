{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from dataloader import InsectDatamodule\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "import torch\n",
    "import IPython.display as ipd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = InsectDatamodule(csv_paths=['../data/Cicadidae.csv', '../data/Orthoptera.csv'], batch_size=10)\n",
    "train_dataloader = datamodule.train_dataloader()\n",
    "\n",
    "metadata = train_dataloader.dataset.get_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global parameters for axis labels and tick sizes\n",
    "plt.rcParams['axes.labelsize'] = 18  # Adjust the size of the axis labels\n",
    "plt.rcParams['xtick.labelsize'] = 12  # Adjust the size of the x-axis tick labels\n",
    "plt.rcParams['ytick.labelsize'] = 12  # Adjust the size of the y-axis tick labels\n",
    "plt.rcParams['axes.titlesize'] = 20  # Adjust the size of the title\n",
    "# plt.rcParams['axes.titleweight'] = 'bold' # Make the title bold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Visualization of the Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(tensor):\n",
    "    return (tensor - tensor.min()) / (tensor.max() - tensor.min())\n",
    "\n",
    "def plot_transformation(path: str,\n",
    "            index: int,\n",
    "            n_fft: int, \n",
    "            top_db: int | None, \n",
    "            n_mels: int, \n",
    "            pad_length: int = 0, \n",
    "            show_audiosample: bool = False, \n",
    "            show_waveform: bool = False\n",
    "            ):\n",
    "\n",
    "    # loading the sample\n",
    "    waveform, samplerate = train_dataloader.dataset.load_sample(path)\n",
    "\n",
    "    # displaying the audio sample if true\n",
    "    if show_audiosample:\n",
    "        ipd.display(ipd.Audio(waveform.numpy()[0], rate=samplerate))\n",
    "\n",
    "\n",
    "    # zero padding the waveform if needed\n",
    "    if pad_length > 0:\n",
    "\n",
    "        pad_samples = int(pad_length * samplerate)\n",
    "        waveform = torch.nn.functional.pad(waveform, pad=(pad_samples, 0, 0, 0))\n",
    "\n",
    "\n",
    "    # Displaying Waveform if true\n",
    "    if show_waveform:\n",
    "\n",
    "        time = np.arange(0, len(waveform[0])) / samplerate\n",
    "\n",
    "        plt.plot(time, waveform[0, :])\n",
    "        plt.title('Waveform')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.show()\n",
    "\n",
    "    # creating the mel spectrogram\n",
    "    mel = torchaudio.transforms.MelSpectrogram(n_fft=n_fft, \n",
    "                                            hop_length=int(n_fft/2), \n",
    "                                            win_length=n_fft, \n",
    "                                            n_mels=n_mels\n",
    "                                            )(waveform)\n",
    "\n",
    "    # transforming the mel spectrogram with amplitude to db\n",
    "    mel_db = torchaudio.transforms.AmplitudeToDB(top_db=top_db)(mel)\n",
    "\n",
    "    # normalizing the transformed mel spectrogram\n",
    "    mel_db_norm = normalize(mel_db)\n",
    "\n",
    "    # creating the spectrogram\n",
    "    spec = torchaudio.transforms.Spectrogram(n_fft=n_fft, \n",
    "                                            hop_length=int(n_fft/2), \n",
    "                                            win_length=n_fft\n",
    "                                            )(waveform)\n",
    "\n",
    "    # transforming the spectrogram with amplitude to db\n",
    "    spec_db = torchaudio.transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "\n",
    "    # normalizing the transformed spectrogram\n",
    "    spec_db_norm = normalize(spec_db)\n",
    "\n",
    "    #setting up the plot\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # plotting subplots\n",
    "    ax[0].imshow(spec_db_norm.numpy().squeeze(), origin='lower', aspect='auto')\n",
    "    ax[0].set_title('Spectrogram')\n",
    "    fig.colorbar(ax[0].imshow(spec_db_norm.numpy().squeeze(), origin='lower', aspect='auto'), ax=ax[0])\n",
    "\n",
    "    ax[1].imshow(mel_db_norm.numpy().squeeze(), origin='lower', aspect='auto')\n",
    "    ax[1].set_title('Mel spectrogram')\n",
    "    fig.colorbar(ax[1].imshow(mel_db_norm.numpy().squeeze(), origin='lower', aspect='auto'), ax=ax[1])\n",
    "\n",
    "    # creating a legend:\n",
    "    text = f'sample_index: {index}, n_fft: {n_fft}, n_mels: {n_mels}, top_db: {top_db}'\n",
    "\n",
    "    # displaying the plot\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.2)  # adjust the bottom margin\n",
    "    # plt.text(0.02, 0.1, text, ha='left', va='top', transform=fig.transFigure)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_path = \"../LaTeX/figures/\"                                    \n",
    "# figure_path = None\n",
    "\n",
    "# setting up the parameters\n",
    "index=26\n",
    "n_fft = 1024\n",
    "n_mels = 64\n",
    "top_db = None\n",
    "pad_length = 0\n",
    "show_audiosample = False\n",
    "show_waveform = False\n",
    "\n",
    "path = metadata['path'][index]\n",
    "\n",
    "fig = plot_transformation(path=path,\n",
    "        index=index,\n",
    "        n_fft=n_fft, \n",
    "        top_db=top_db, \n",
    "        n_mels=n_mels, \n",
    "        pad_length=pad_length, \n",
    "        show_audiosample=show_audiosample, \n",
    "        show_waveform=show_waveform)\n",
    "\n",
    "if figure_path is not None:\n",
    "        fig.savefig(f'{figure_path}compare_spectrogram.pdf')\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting  Visualizations for best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_best_model = '../logs/main_run/mel064_nblock4_lr0.001_ks5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ytrue_yhat(model_path: str, data_set_selection: list = [\"test\"]):\n",
    "\n",
    "    path = f'{model_path}/predictions.csv'\n",
    "    data = pd.read_csv(path)\n",
    "\n",
    "    filtered_data = data[data['data_set'].isin(data_set_selection)]\n",
    "\n",
    "    y_true = filtered_data['class_ID']\n",
    "    y_pred = filtered_data['class_ID_pred']\n",
    "\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_path = \"../LaTeX/figures/\"\n",
    "# figure_path = None\n",
    "\n",
    "\n",
    "y_true, y_pred = get_ytrue_yhat(path_best_model)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(ax=ax, colorbar=False)\n",
    "\n",
    "# Label the axes\n",
    "ax.set_xlabel('Predicted ClassID')\n",
    "ax.set_ylabel('True ClassID')\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap='viridis')\n",
    "cbar = fig.colorbar(im, cax=cax)\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "if figure_path is None:\n",
    "    plt.show()\n",
    "else:\n",
    "    fig.savefig(f'{figure_path}confusion_matrix_best.pdf')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Hyperparameter Tuning of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrrr}\n",
      "\\toprule\n",
      "\\textbf{n\\_mels} & \\textbf{n\\_res\\_blocks} & \\textbf{learning\\_rate} & \\textbf{kernel\\_size}& \\textbf{trainable\\_params} & \\textbf{trained\\_epochs} & \\textbf{accuracy} \\\\\n",
      "\\midrule\n",
      "64 & 4 & 0.001 & 5 & 832,912 & 1018 & 0.649 \\\\\n",
      "64 & 3 & 0.001 & 5 & 207,376 & 505 & 0.608 \\\\\n",
      "-1 & 2 & 0.001 & 5 & 50,256 & 640 & 0.608 \\\\\n",
      "-1 & 3 & 0.0001 & 3 & 78,224 & 897 & 0.581 \\\\\n",
      "-1 & 2 & 0.001 & 3 & 19,408 & 469 & 0.568 \\\\\n",
      "-1 & 4 & 0.0001 & 3 & 310,544 & 891 & 0.568 \\\\\n",
      "-1 & 3 & 0.0001 & 7 & 401,104 & 760 & 0.568 \\\\\n",
      "-1 & 4 & 0.0001 & 5 & 832,912 & 672 & 0.554 \\\\\n",
      "64 & 4 & 0.0001 & 5 & 832,912 & 371 & 0.554 \\\\\n",
      "64 & 3 & 0.001 & 7 & 401,104 & 350 & 0.541 \\\\\n",
      "-1 & 2 & 0.0001 & 7 & 96,528 & 1198 & 0.541 \\\\\n",
      "64 & 3 & 0.0001 & 7 & 401,104 & 536 & 0.541 \\\\\n",
      "64 & 3 & 0.0001 & 3 & 78,224 & 1115 & 0.541 \\\\\n",
      "-1 & 3 & 0.001 & 5 & 207,376 & 394 & 0.527 \\\\\n",
      "-1 & 3 & 0.001 & 3 & 78,224 & 456 & 0.500 \\\\\n",
      "-1 & 4 & 0.001 & 3 & 310,544 & 562 & 0.486 \\\\\n",
      "64 & 2 & 0.001 & 5 & 50,256 & 661 & 0.473 \\\\\n",
      "64 & 2 & 0.0001 & 5 & 50,256 & 892 & 0.473 \\\\\n",
      "64 & 4 & 0.0001 & 7 & 1,616,464 & 273 & 0.459 \\\\\n",
      "-1 & 3 & 0.0001 & 5 & 207,376 & 531 & 0.459 \\\\\n",
      "-1 & 2 & 0.0001 & 3 & 19,408 & 1138 & 0.459 \\\\\n",
      "64 & 2 & 0.0001 & 3 & 19,408 & 1354 & 0.446 \\\\\n",
      "64 & 4 & 0.001 & 3 & 310,544 & 408 & 0.419 \\\\\n",
      "64 & 3 & 0.0001 & 5 & 207,376 & 395 & 0.419 \\\\\n",
      "64 & 3 & 0.001 & 3 & 78,224 & 474 & 0.405 \\\\\n",
      "64 & 4 & 0.0001 & 3 & 310,544 & 330 & 0.392 \\\\\n",
      "-1 & 2 & 0.001 & 7 & 96,528 & 375 & 0.378 \\\\\n",
      "64 & 4 & 0.001 & 7 & 1,616,464 & 403 & 0.378 \\\\\n",
      "64 & 2 & 0.001 & 7 & 96,528 & 229 & 0.378 \\\\\n",
      "64 & 2 & 0.001 & 3 & 19,408 & 455 & 0.378 \\\\\n",
      "-1 & 4 & 0.0001 & 7 & 1,616,464 & 296 & 0.378 \\\\\n",
      "64 & 2 & 0.0001 & 7 & 96,528 & 545 & 0.351 \\\\\n",
      "-1 & 2 & 0.0001 & 5 & 50,256 & 432 & 0.338 \\\\\n",
      "-1 & 4 & 0.001 & 5 & 832,912 & 290 & 0.284 \\\\\n",
      "-1 & 4 & 0.001 & 7 & 1,616,464 & 145 & 0.230 \\\\\n",
      "-1 & 3 & 0.001 & 7 & 401,104 & 268 & 0.176 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_path = None\n",
    "# table_path = \"../LaTeX/tables/\"\n",
    "\n",
    "eval_csv_path = \"../logs/main_run/evaluation/eval_summary.csv\"\n",
    "\n",
    "# Loading the evaluation data\n",
    "eval_data = pd.read_csv(eval_csv_path)\n",
    "eval_data_selected = eval_data[['n_mels', 'n_res_blocks', 'learning_rate', 'kernel_size', 'num_trainable_params', 'trained_epochs', 'accuracy']]\n",
    "eval_data_selected.loc[:, 'n_mels'] = eval_data_selected['n_mels'].fillna(-1).astype(int)\n",
    "eval_data_selected_arranged = eval_data_selected.sort_values(by='accuracy', ascending=False)\n",
    "\n",
    "# Formatting the DataFrame\n",
    "eval_data_selected_arranged['n_mels'] = eval_data_selected_arranged['n_mels'].apply(lambda x: f\"{x:.0f}\")\n",
    "eval_data_selected_arranged['learning_rate'] = eval_data_selected_arranged['learning_rate'].apply(lambda x: f\"{x:.3g}\")\n",
    "eval_data_selected_arranged['accuracy'] = eval_data_selected_arranged['accuracy'].apply(lambda x: f\"{x:.3f}\")\n",
    "eval_data_selected_arranged['num_trainable_params'] = eval_data_selected_arranged['num_trainable_params'].apply(lambda x: f\"{int(x):,}\")\n",
    "\n",
    "# Convert DataFrame to LaTeX table\n",
    "latex_table = eval_data_selected_arranged.to_latex(\n",
    "    index=False, \n",
    "    column_format=\"rrrrrrr\"\n",
    ")\n",
    "\n",
    "# Manually replace the header row to make it bold\n",
    "old_header = \"n_mels & n_res_blocks & learning_rate & kernel_size & num_trainable_params & trained_epochs & accuracy \\\\\\\\\"\n",
    "new_header = \"\\\\textbf{n\\\\_mels} & \\\\textbf{n\\\\_res\\\\_blocks} & \\\\textbf{learning\\\\_rate} & \\\\textbf{kernel\\\\_size}& \\\\textbf{trainable\\\\_params} & \\\\textbf{trained\\\\_epochs} & \\\\textbf{accuracy} \\\\\\\\\"\n",
    "latex_table = latex_table.replace(old_header, new_header)\n",
    "\n",
    "\n",
    "# Saving the table\n",
    "if table_path is None:\n",
    "    print(latex_table)\n",
    "else:\n",
    "    with open(f'{table_path}hyperparameters_results.tex', 'w') as f:\n",
    "        f.write(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating a table showing the label and names of the insects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_path = None\n",
    "table_path = \"../LaTeX/tables/\"\n",
    "\n",
    "unique_class_id = metadata[['class_id', 'species']].drop_duplicates(subset=['class_id']).sort_values(by='class_id')\n",
    "\n",
    "# Split data into two parts\n",
    "half = len(unique_class_id) // 2 + len(unique_class_id) % 2\n",
    "first_half = unique_class_id.iloc[:half].reset_index(drop=True)\n",
    "second_half = unique_class_id.iloc[half:].reset_index(drop=True)\n",
    "\n",
    "# Concatenate first half and second half side by side\n",
    "concatenated = pd.concat([first_half, second_half], axis=1)\n",
    "\n",
    "# Adjust column names for LaTeX output\n",
    "concatenated.columns = ['ClassID', 'Species', 'ClassID', 'Species']\n",
    "\n",
    "# Convert to LaTeX\n",
    "latex_table = concatenated.to_latex(\n",
    "    index=False, \n",
    "    column_format=\"rlrl\",\n",
    "    header=True\n",
    ")\n",
    "\n",
    "\n",
    "# Saving the table\n",
    "if table_path is None:\n",
    "    print(latex_table)\n",
    "else:\n",
    "    with open(f'{table_path}ClassID_legend.tex', 'w') as f:\n",
    "        f.write(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
